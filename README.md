# Automated Grading Script for Heroes API Spike Test

Hello everyone! This repository contains a Python script designed to automate the grading process for the Heroes API spike tests.

## :warning: Important Update regarding `HeroControllerTest#testCreateHeroFailed`

While grading, an important observation was made regarding the spike assignment on Heroes API. There appears to be a consistent test failure across multiple student submissions, specifically tied to the `HeroControllerTest#testCreateHeroFailed` test case. Given the widespread nature of this failure, it's believed that there might be an issue with the test case itself or potentially some ambiguity in the assignment specifications.

### Key Points:
- The test is designed to check if hero creation fails under specific conditions.
- This failure is prevalent in submissions across different sections.
- It could potentially impact the grades of numerous students.

### Recommendations:
1. **Reviewing the Test Case**: Before finalizing grades, please double-check the `HeroControllerTest#testCreateHeroFailed` test case.
2. **Adjusting Grading**: Consider adjusting the grading criteria for this specific test, to ensure fairness.
3. **Student Communication**: Inform students in your respective sections about this issue to alleviate concerns about this particular test failure.

## Usage of the Script

This script was created to automate the grading process, considering the specific test anomaly mentioned above. To use the script, follow the instructions below:

```bash
# To be added based on the script's specifics
